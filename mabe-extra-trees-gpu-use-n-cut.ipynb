{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":59156,"databundleVersionId":13874099,"sourceType":"competition"},{"sourceId":14052315,"sourceType":"datasetVersion","datasetId":8938720},{"sourceId":675578,"sourceType":"modelInstanceVersion","modelInstanceId":511758,"modelId":526417}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Update of AmbrosMs' great notebook\n# Removes the constant FPS assumption; handles variable frame timing\n# Added full GPU suppoprt and extra trees/feats\n\nverbose = True\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport itertools\nimport warnings\nimport json\nimport os, random\nimport gc, re, math\nimport hashlib\nimport joblib\nimport lightgbm\nfrom collections import defaultdict\nimport polars as pl\nfrom scipy import signal, stats\nfrom typing import Dict, Optional, Tuple\nfrom time import perf_counter \nimport optuna\nfrom sklearn.base import ClassifierMixin, BaseEstimator, clone\nfrom sklearn.model_selection import cross_val_predict, GroupKFold, StratifiedKFold\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import f1_score\n\nwarnings.filterwarnings('ignore')\nUSE_GPU = (\"KAGGLE_KERNEL_RUN_TYPE\" in __import__(\"os\").environ) and (__import__(\"shutil\").which(\"nvidia-smi\") is not None)\nprint(f'Using GPU? {USE_GPU}')\n\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n \nSEED = 1234\nN_CUT = 1_500_000\nLEAST_POS_PERC = 0.05\n_safe_token = re.compile(r'[^A-Za-z0-9]+')\n# ---- runtime switches ----\nONLY_TUNE_THRESHOLDS = True     # True: only search thresholds and save; skip training/inference/submission\nUSE_ADAPTIVE_THRESHOLDS = True   # False: use constant 0.27 for all actions, skip tuning/loading\nLOAD_THRESHOLDS = False          # True: load thresholds from THRESHOLD_DIR instead of tuning\nLOAD_MODELS = False              # True: load models from MODEL_DIR instead of training\nCHECK_LOAD = False\nTHRESHOLD_DIR = \"./threshold\"\nMODEL_DIR = \"./models\"\nTHRESHOLD_LOAD_DIR = \"/kaggle/input/xgb-threshold/threshold\"      # load thresholds from here\nMODEL_LOAD_DIR = \"/kaggle/input/xgb-models/other/default/2/models\"              # load models from here","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:28:19.301021Z","iopub.execute_input":"2025-11-10T09:28:19.301665Z","iopub.status.idle":"2025-11-10T09:28:25.286798Z","shell.execute_reply.started":"2025-11-10T09:28:19.301639Z","shell.execute_reply":"2025-11-10T09:28:25.286052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# MODIFIED: imports for ST-GCN\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- SEED EVERYTHING -----\nos.environ[\"PYTHONHASHSEED\"] = str(SEED)      # has to be set very early\n\nrnd = np.random.RandomState(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\n\ndef _make_xgb(**kw):\n    kw.setdefault(\"random_state\", SEED)\n    kw.setdefault(\"tree_method\", \"gpu_hist\" if USE_GPU else \"hist\")\n    # kw.setdefault(\"deterministic_histogram\", True)\n    return XGBClassifier(**kw)\n\ndef _slugify(text: str) -> str:\n    \"\"\"Make a filename-safe slug from the body_parts_tracked string (truncate + hash to avoid long paths).\"\"\"\n    base = _safe_token.sub('-', text).strip('-') or \"default\"\n    max_len = 80\n    if len(base) <= max_len:\n        return base\n    digest = hashlib.md5(text.encode('utf-8')).hexdigest()[:8]\n    return f\"{base[:max_len - len(digest) - 1]}-{digest}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:28:25.288258Z","iopub.execute_input":"2025-11-10T09:28:25.288688Z","iopub.status.idle":"2025-11-10T09:28:25.294825Z","shell.execute_reply.started":"2025-11-10T09:28:25.28867Z","shell.execute_reply":"2025-11-10T09:28:25.294145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================= StratifiedSubsetClassifier =================\nclass StratifiedSubsetClassifierWEval(ClassifierMixin, BaseEstimator):\n    def __init__(self,\n                 estimator,\n                 n_samples=None,\n                 random_state: int = 42,\n                 valid_size: float = 0.10,\n                 val_cap_ratio: float = 0.25,\n                 es_rounds: \"int|str\" = \"auto\",\n                 es_metric: str = \"auto\"):\n        self.estimator = estimator\n        self.n_samples = (int(n_samples) if (n_samples is not None) else None)\n        self.random_state = random_state\n        self.valid_size = float(valid_size)\n        self.val_cap_ratio = float(val_cap_ratio)\n        self.es_rounds = es_rounds\n        self.es_metric = es_metric\n \n    # -------------------------- API --------------------------\n    def fit(self, X: pd.DataFrame, y):\n        y = np.asarray(y)\n        n_total = len(y); assert n_total == len(X)\n\n        tr_idx, va_idx = self._compute_train_val_indices(y, n_total)\n        Xtr = X.iloc[tr_idx]; ytr = y[tr_idx]\n\n        Xtr = Xtr.to_numpy(np.float32, copy=False)\n\n        Xva = yva = None\n        if va_idx is not None and len(va_idx) > 0:\n            Xva = X.iloc[va_idx].to_numpy(np.float32, copy=False); yva = y[va_idx]\n\n        # Compute pos_rate on VALIDATION (what ES monitors)\n        pos_rate = None\n        if yva is not None and len(yva) > 0:\n            pos_rate = float(np.mean(yva == 1))\n\n        # Decide metric & patience\n        metric = self._choose_metric(pos_rate)\n        patience = self._choose_patience(pos_rate)\n\n        # Apply imbalance knobs per library\n        if self._is_xgb(self.estimator):\n            # scale_pos_weight = n_neg / n_pos on TRAIN\n            n_pos = max(1, int((ytr == 1).sum()))\n            n_neg = max(1, len(ytr) - n_pos)\n            self.estimator.set_params(scale_pos_weight=(n_neg / n_pos))\n            self.estimator.set_params(eval_metric=metric)\n\n        elif self._is_catboost(self.estimator):\n            # GPU-safe auto balancing\n            try: self.estimator.set_params(auto_class_weights=\"Balanced\")\n            except Exception: pass\n            try: self.estimator.set_params(eval_metric=metric)\n            except Exception: pass\n\n        # Fit with ES if we have any validation (single-class OK with Logloss)\n        has_valid = (Xva is not None and len(yva) > 0)\n        if has_valid and self._is_xgb(self.estimator):\n            import xgboost as xgb\n            self.estimator.fit(\n                Xtr, ytr,\n                eval_set=[(Xva, yva)],\n                verbose=False,\n                callbacks=[xgb.callback.EarlyStopping(\n                    rounds=int(patience),\n                    metric_name=metric,\n                    data_name=\"validation_0\",\n                    save_best=True\n                )]\n            )\n        elif has_valid and self._is_catboost(self.estimator):\n            from catboost import Pool\n            self.estimator.set_params(\n                use_best_model=True,\n                od_type=\"Iter\",\n                od_wait=int(patience),\n                custom_metric=[\"PRAUC:type=Classic;hints=skip_train~true\"],\n            )\n            self.estimator.fit(\n                Xtr, ytr,\n                eval_set=Pool(Xva, yva),\n                verbose=False,\n                metric_period=50\n            )\n        else:\n            # Fall back: train on train split without ES\n            self.estimator.fit(Xtr, ytr)\n\n        self.classes_ = getattr(self.estimator, \"classes_\", np.array([0, 1]))\n        self._tr_idx_ = tr_idx; self._va_idx_ = va_idx; self._pos_rate_ = pos_rate\n        return self\n\n    def predict_proba(self, X: pd.DataFrame):\n        return self.estimator.predict_proba(X)\n\n    def predict(self, X: pd.DataFrame):\n        return self.estimator.predict(X)\n\n    # -------------------------- helpers --------------------------\n    def _compute_train_val_indices(self, y: np.ndarray, n_total: int):\n        rng = np.random.default_rng(self.random_state)\n        n_classes = np.unique(y).size\n\n        def full_data_split():\n            if self.valid_size <= 0 or n_classes < 2:\n                idx = rng.permutation(n_total); return idx, None\n            sss = StratifiedShuffleSplit(n_splits=1, test_size=self.valid_size, random_state=self.random_state)\n            tr, va = next(sss.split(np.zeros(n_total, dtype=np.int8), y))\n            return tr, va\n\n        if self.n_samples is None or self.n_samples >= n_total:\n            return full_data_split()\n\n        # Use n_samples for train; build val from remainder (capped)\n        sss_tr = StratifiedShuffleSplit(n_splits=1, train_size=self.n_samples, random_state=self.random_state)\n        tr_idx, rest_idx = next(sss_tr.split(np.zeros(n_total, dtype=np.int8), y))\n        remaining = len(rest_idx)\n\n        min_val_needed = int(np.ceil(self.n_samples * max(self.valid_size, 0.0)))\n        val_cap = max(min_val_needed, int(round(self.val_cap_ratio * self.n_samples)))\n        want_val = min(remaining, val_cap)\n\n        y_rest = y[rest_idx]\n        if remaining < min_val_needed or np.unique(y_rest).size < 2 or self.valid_size <= 0:\n            return full_data_split()\n\n        sss_val = StratifiedShuffleSplit(n_splits=1, train_size=want_val, random_state=self.random_state)\n        try:\n            va_sel, _ = next(sss_val.split(np.zeros(remaining, dtype=np.int8), y_rest))\n        except ValueError:\n            return full_data_split()\n\n        va_idx = rest_idx[va_sel]\n        return tr_idx, va_idx\n\n    def _choose_metric(self, pos_rate=0.01) -> str:\n        if self.es_metric != \"auto\":\n            return self.es_metric\n        if pos_rate is None or pos_rate == 0.0 or pos_rate == 1.0:\n            return \"logloss\" if self._is_xgb(self.estimator) else \"Logloss\"\n        return \"aucpr\" if self._is_xgb(self.estimator) else \"PRAUC:type=Classic\"\n\n    def _choose_patience(self, pos_rate: Optional[float]) -> int:\n        if isinstance(self.es_rounds, int):\n            return self.es_rounds\n        try:\n            n_estimators = (int(self.estimator.get_params().get(\"n_estimators\", 200))\n                            if self._is_xgb(self.estimator)\n                            else int(self.estimator.get_params().get(\"iterations\", 500)))\n        except Exception:\n            n_estimators = 200\n        base = max(30, int(round(0.20 * (n_estimators or 200))))\n        if pos_rate is None:\n            return base\n        if pos_rate < 0.005:   # <0.5%\n            return int(round(base * 1.75))\n        if pos_rate < 0.02:    # <2%\n            return int(round(base * 1.40))\n        return base\n\n    @staticmethod\n    def _is_xgb(est):\n        name = est.__class__.__name__.lower(); mod = getattr(est, \"__module__\", \"\")\n        return \"xgb\" in name or \"xgboost\" in mod or hasattr(est, \"get_xgb_params\")\n\n    @staticmethod\n    def _is_catboost(est):\n        name = est.__class__.__name__.lower(); mod = getattr(est, \"__module__\", \"\")\n        return \"catboost\" in name or \"catboost\" in mod or hasattr(est, \"get_all_params\")\n\n\nclass StratifiedSubsetClassifier(ClassifierMixin, BaseEstimator):\n    def __init__(self, estimator, n_samples, random_state=SEED):\n        self.estimator = estimator\n        self.n_samples = n_samples and int(n_samples)\n        self.random_state = random_state\n\n    def fit(self, X, y):\n        y = np.asarray(y)\n        n_total = len(y)\n\n        if self.n_samples is None or self.n_samples >= n_total:\n            rng = np.random.default_rng(self.random_state)\n            idx = rng.permutation(n_total)\n        else:\n            sss = StratifiedShuffleSplit(\n                n_splits=1, train_size=self.n_samples, random_state=self.random_state\n            )\n            idx, _ = next(sss.split(np.zeros(n_total, dtype=np.int8), y))\n\n        Xn = X.iloc[idx]\n        Xn = Xn.to_numpy(np.float32, copy=False)\n        yn = y[idx]\n\n        self.estimator.fit(Xn, yn)\n        self.classes_ = getattr(self.estimator, \"classes_\", np.array([0, 1]))\n        return self\n\n    def predict_proba(self, X):\n        return self.estimator.predict_proba(X)\n\n    def predict(self, X):\n        return self.estimator.predict(X)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:28:25.295522Z","iopub.execute_input":"2025-11-10T09:28:25.295773Z","iopub.status.idle":"2025-11-10T09:28:25.318849Z","shell.execute_reply.started":"2025-11-10T09:28:25.295753Z","shell.execute_reply":"2025-11-10T09:28:25.318139Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==================== SCORING FUNCTIONS ====================\n\nclass HostVisibleError(Exception):\n    pass\n\ndef single_lab_f1(lab_solution: pl.DataFrame, lab_submission: pl.DataFrame, beta: float = 1) -> float:\n    label_frames: defaultdict[str, set[int]] = defaultdict(set)\n    prediction_frames: defaultdict[str, set[int]] = defaultdict(set)\n\n    for row in lab_solution.to_dicts():\n        label_frames[row['label_key']].update(range(row['start_frame'], row['stop_frame']))\n\n    for video in lab_solution['video_id'].unique():\n        active_labels: str = lab_solution.filter(pl.col('video_id') == video)['behaviors_labeled'].first()\n        active_labels: set[str] = set(json.loads(active_labels))\n        predicted_mouse_pairs: defaultdict[str, set[int]] = defaultdict(set)\n\n        for row in lab_submission.filter(pl.col('video_id') == video).to_dicts():\n            if ','.join([str(row['agent_id']), str(row['target_id']), row['action']]) not in active_labels:\n                continue\n           \n            new_frames = set(range(row['start_frame'], row['stop_frame']))\n            new_frames = new_frames.difference(prediction_frames[row['prediction_key']])\n            prediction_pair = ','.join([str(row['agent_id']), str(row['target_id'])])\n            if predicted_mouse_pairs[prediction_pair].intersection(new_frames):\n                raise HostVisibleError('Multiple predictions for the same frame from one agent/target pair')\n            prediction_frames[row['prediction_key']].update(new_frames)\n            predicted_mouse_pairs[prediction_pair].update(new_frames)\n\n    tps = defaultdict(int)\n    fns = defaultdict(int)\n    fps = defaultdict(int)\n    for key, pred_frames in prediction_frames.items():\n        action = key.split('_')[-1]\n        matched_label_frames = label_frames[key]\n        tps[action] += len(pred_frames.intersection(matched_label_frames))\n        fns[action] += len(matched_label_frames.difference(pred_frames))\n        fps[action] += len(pred_frames.difference(matched_label_frames))\n\n    distinct_actions = set()\n    for key, frames in label_frames.items():\n        action = key.split('_')[-1]\n        distinct_actions.add(action)\n        if key not in prediction_frames:\n            fns[action] += len(frames)\n\n    action_f1s = []\n    for action in distinct_actions:\n        if tps[action] + fns[action] + fps[action] == 0:\n            action_f1s.append(0)\n        else:\n            action_f1s.append((1 + beta**2) * tps[action] / ((1 + beta**2) * tps[action] + beta**2 * fns[action] + fps[action]))\n    return sum(action_f1s) / len(action_f1s)\n\ndef mouse_fbeta(solution: pd.DataFrame, submission: pd.DataFrame, beta: float = 1) -> float:\n    if len(solution) == 0 or len(submission) == 0:\n        raise ValueError('Missing solution or submission data')\n\n    expected_cols = ['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']\n\n    for col in expected_cols:\n        if col not in solution.columns:\n            raise ValueError(f'Solution is missing column {col}')\n        if col not in submission.columns:\n            raise ValueError(f'Submission is missing column {col}')\n\n    solution: pl.DataFrame = pl.DataFrame(solution)\n    submission: pl.DataFrame = pl.DataFrame(submission)\n    assert (solution['start_frame'] <= solution['stop_frame']).all()\n    assert (submission['start_frame'] <= submission['stop_frame']).all()\n    solution_videos = set(solution['video_id'].unique())\n    submission = submission.filter(pl.col('video_id').is_in(solution_videos))\n\n    solution = solution.with_columns(\n        pl.concat_str(\n            [\n                pl.col('video_id').cast(pl.Utf8),\n                pl.col('agent_id').cast(pl.Utf8),\n                pl.col('target_id').cast(pl.Utf8),\n                pl.col('action'),\n            ],\n            separator='_',\n        ).alias('label_key'),\n    )\n    submission = submission.with_columns(\n        pl.concat_str(\n            [\n                pl.col('video_id').cast(pl.Utf8),\n                pl.col('agent_id').cast(pl.Utf8),\n                pl.col('target_id').cast(pl.Utf8),\n                pl.col('action'),\n            ],\n            separator='_',\n        ).alias('prediction_key'),\n    )\n\n    lab_scores = []\n    for lab in solution['lab_id'].unique():\n        lab_solution = solution.filter(pl.col('lab_id') == lab).clone()\n        lab_videos = set(lab_solution['video_id'].unique())\n        lab_submission = submission.filter(pl.col('video_id').is_in(lab_videos)).clone()\n        lab_scores.append(single_lab_f1(lab_solution, lab_submission, beta=beta))\n\n    return sum(lab_scores) / len(lab_scores)\n\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, beta: float = 1) -> float:\n    solution = solution.drop(row_id_column_name, axis='columns', errors='ignore')\n    submission = submission.drop(row_id_column_name, axis='columns', errors='ignore')\n    return mouse_fbeta(solution, submission, beta=beta)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-11-10T09:28:25.319542Z","iopub.execute_input":"2025-11-10T09:28:25.319735Z","iopub.status.idle":"2025-11-10T09:28:25.338898Z","shell.execute_reply.started":"2025-11-10T09:28:25.319719Z","shell.execute_reply":"2025-11-10T09:28:25.338191Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==================== DATA LOADING ====================\n\ntrain = pd.read_csv('/kaggle/input/MABe-mouse-behavior-detection/train.csv')\n\n# drop likely-sleeping MABe22 clips: condition == \"lights on\"\ntrain = train.loc[~(train['lab_id'].astype(str).str.contains('MABe22', na=False) &\n                    train['mouse1_condition'].astype(str).str.lower().eq('lights on'))].copy()\n\ntrain['n_mice'] = 4 - train[['mouse1_strain', 'mouse2_strain', 'mouse3_strain', 'mouse4_strain']].isna().sum(axis=1)\n\ntest = pd.read_csv('/kaggle/input/MABe-mouse-behavior-detection/test.csv')\ntest['sleeping'] = (\n    test['lab_id'].astype(str).str.contains('MABe22', na=False) &\n    test['mouse1_condition'].astype(str).str.lower().eq('lights on')\n)\ntest['n_mice'] = 4 - test[['mouse1_strain','mouse2_strain','mouse3_strain','mouse4_strain']].isna().sum(axis=1)\n\nbody_parts_tracked_list = list(np.unique(train.body_parts_tracked))\n\ndrop_body_parts = ['headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright', \n                   'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright',                  \n                   'spine_1', 'spine_2', 'tail_middle_1', 'tail_middle_2', 'tail_midpoint']\n\n_sex_cols = [f'mouse{i}_sex' for i in range(1,5)]\n_train_sex_lut = (train[['video_id'] + _sex_cols].drop_duplicates('video_id')\n                  .set_index('video_id').to_dict('index'))\n_test_sex_lut  = (test[['video_id']  + _sex_cols].drop_duplicates('video_id')\n                  .set_index('video_id').to_dict('index'))\n_FEATURE_TEMPLATES = {}\n\ndef generate_mouse_data(dataset, traintest, traintest_directory=None,\n                        generate_single=True, generate_pair=True):\n    assert traintest in ['train', 'test']\n    if traintest_directory is None:\n        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n\n    def _to_num(x):\n        if isinstance(x, (int, np.integer)): return int(x)\n        m = re.search(r'(\\d+)$', str(x))\n        return int(m.group(1)) if m else None\n\n    for _, row in dataset.iterrows():\n        lab_id   = row.lab_id\n        video_id = row.video_id\n        fps      = float(row.frames_per_second)\n        n_mice   = int(row.n_mice)\n        arena_w  = float(row.get('arena_width_cm', np.nan))\n        arena_h  = float(row.get('arena_height_cm', np.nan))\n        sleeping = bool(getattr(row, 'sleeping', False))\n        arena_shape = row.get('arena_shape', 'rectangular')\n\n        if not isinstance(row.behaviors_labeled, str):\n            continue\n\n        # ---- tracking ----\n        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n        vid = pd.read_parquet(path)\n        if len(np.unique(vid.bodypart)) > 5:\n            vid = vid.query(\"~ bodypart.isin(@drop_body_parts)\")\n        pvid = vid.pivot(columns=['mouse_id','bodypart'], index='video_frame', values=['x','y'])\n        del vid\n        pvid = pvid.reorder_levels([1,2,0], axis=1).T.sort_index().T\n        pvid = (pvid / float(row.pix_per_cm_approx)).astype('float32', copy=False)\n\n        # available mouse_id labels in tracking (could be ints or strings)\n        avail = list(pvid.columns.get_level_values('mouse_id').unique())\n        avail_set = set(avail) | set(map(str, avail)) | {f\"mouse{_to_num(a)}\" for a in avail if _to_num(a) is not None}\n\n        def _resolve(agent_str):\n            \"\"\"Return the matching mouse_id label present in pvid (int or str), or None.\"\"\"\n            m = re.search(r'(\\d+)$', str(agent_str))\n            cand = [agent_str]\n            if m:\n                n = int(m.group(1))\n                cand = [n, n-1, str(n), f\"mouse{n}\", agent_str]  # try 1-based, 0-based, str, canonical\n            for c in cand:\n                if c in avail_set:  # compare within unified set\n                    # return the exact label used in columns\n                    if c in set(avail): return c\n                    # map back to the exact label that exists (int preferred)\n                    for a in avail:\n                        if str(a) == str(c) or f\"mouse{_to_num(a)}\" == str(c):\n                            return a\n            return None\n\n        # ---- behaviors ----\n        vb = json.loads(row.behaviors_labeled)\n        vb = sorted(list({b.replace(\"'\", \"\") for b in vb}))\n        vb = pd.DataFrame([b.split(',') for b in vb], columns=['agent','target','action'])\n        vb['agent']  = vb['agent'].astype(str)\n        vb['target'] = vb['target'].astype(str)\n        vb['action'] = vb['action'].astype(str).str.lower()\n\n        if traintest == 'train':\n            try:\n                annot = pd.read_parquet(path.replace('train_tracking', 'train_annotation'))\n            except FileNotFoundError:\n                continue\n\n        def _mk_meta(index, agent_id, target_id):\n            m = pd.DataFrame({\n                'lab_id':        lab_id,\n                'video_id':      video_id,\n                'agent_id':      agent_id,\n                'target_id':     target_id,\n                'video_frame':   index.astype('int32', copy=False),\n                'frames_per_second': np.float32(fps),\n                'sleeping':      sleeping,\n                'arena_shape':   arena_shape,\n                'arena_width_cm': np.float32(arena_w),\n                'arena_height_cm': np.float32(arena_h),\n                'n_mice':        np.int8(n_mice),\n            })\n            for c in ('lab_id','video_id','agent_id','target_id','arena_shape'):\n                m[c] = m[c].astype('category')\n            # Align index to frame numbers so sampling with .loc on frame ids works.\n            m = m.set_index('video_frame')\n            m['video_frame'] = m.index\n            return m\n\n        # ---------- SINGLE ----------\n        if generate_single:\n            vb_single = vb.query(\"target == 'self'\")\n            for agent_str in pd.unique(vb_single['agent']):\n                col_lab = _resolve(agent_str)\n                if col_lab is None:\n                    # if verbose: print(f\"[skip single] {video_id} missing {agent_str} in tracking (avail={sorted(avail)})\")\n                    continue\n                actions = sorted(vb_single.loc[vb_single['agent'].eq(agent_str), 'action'].unique().tolist())\n                if not actions:\n                    continue\n\n                single = pvid.loc[:, col_lab]\n                meta_df = _mk_meta(single.index, agent_str, 'self')\n\n                if traintest == 'train':\n                    a_num = _to_num(col_lab)\n                    y = pd.DataFrame(False, index=single.index.astype('int32', copy=False), columns=actions)\n                    a_sub = annot.query(\"(agent_id == @a_num) & (target_id == @a_num)\")\n                    for i in range(len(a_sub)):\n                        ar = a_sub.iloc[i]\n                        a = str(ar.action).lower()\n                        if a in y.columns:\n                            y.loc[int(ar['start_frame']):int(ar['stop_frame']), a] = True\n                    yield 'single', single, meta_df, y\n                else:\n                    yield 'single', single, meta_df, actions\n\n        # ---------- PAIR (ONLY LABELED PAIRS) ----------\n        if generate_pair:\n            vb_pair = vb.query(\"target != 'self'\")\n            if len(vb_pair) > 0:\n                allowed_pairs = set(map(tuple, vb_pair[['agent','target']].itertuples(index=False, name=None)))\n\n                for agent_num, target_num in itertools.permutations(\n                        np.unique(pvid.columns.get_level_values('mouse_id')), 2):\n                    agent_str = f\"mouse{_to_num(agent_num)}\"\n                    target_str = f\"mouse{_to_num(target_num)}\"\n                    if (agent_str, target_str) not in allowed_pairs:\n                        continue\n\n                    a_col = _resolve(agent_str)\n                    b_col = _resolve(target_str)\n                    if a_col is None or b_col is None:\n                        # if verbose: print(f\"[skip pair] {video_id} missing {agent_str}->{target_str}\")\n                        continue\n\n                    actions = sorted(\n                        vb_pair.query(\"(agent == @agent_str) & (target == @target_str)\")['action'].unique().tolist()\n                    )\n                    if not actions:\n                        continue\n\n                    pair_xy = pd.concat([pvid[a_col], pvid[b_col]], axis=1, keys=['A','B'])\n                    meta_df = _mk_meta(pair_xy.index, agent_str, target_str)\n\n                    if traintest == 'train':\n                        a_num = _to_num(a_col); b_num = _to_num(b_col)\n                        y = pd.DataFrame(False, index=pair_xy.index.astype('int32', copy=False), columns=actions)\n                        a_sub = annot.query(\"(agent_id == @a_num) & (target_id == @b_num)\")\n                        for i in range(len(a_sub)):\n                            ar = a_sub.iloc[i]\n                            a = str(ar.action).lower()\n                            if a in y.columns:\n                                y.loc[int(ar['start_frame']):int(ar['stop_frame']), a] = True\n                        yield 'pair', pair_xy, meta_df, y\n                    else:\n                        yield 'pair', pair_xy, meta_df, actions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:28:25.340432Z","iopub.execute_input":"2025-11-10T09:28:25.34075Z","iopub.status.idle":"2025-11-10T09:28:25.649463Z","shell.execute_reply.started":"2025-11-10T09:28:25.340736Z","shell.execute_reply":"2025-11-10T09:28:25.64893Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==================== ADAPTIVE THRESHOLDING ====================\n\ndef predict_multiclass_adaptive(pred, meta, action_thresholds=defaultdict(lambda: 0.27)):\n    \"\"\"Adaptive thresholding per action + temporal smoothing\"\"\"\n    # Apply temporal smoothing\n    pred_smoothed = pred.rolling(window=7, min_periods=1, center=True).mean()\n    \n    # Apply per-action thresholds first, then pick max among the valid ones\n    thresholds = np.array([action_thresholds.get(action, 0.27) for action in pred_smoothed.columns], dtype=np.float32)\n    vals = pred_smoothed.values\n    valid = vals >= thresholds  # broadcast per action\n    masked = np.where(valid, vals, -np.inf)\n    ama = masked.argmax(axis=1)\n    all_invalid = ~valid.any(axis=1)\n    ama[all_invalid] = -1\n    ama = pd.Series(ama, index=meta.video_frame)\n    \n    changes_mask = (ama != ama.shift(1)).values\n    ama_changes = ama[changes_mask]\n    meta_changes = meta[changes_mask]\n    mask = ama_changes.values >= 0\n    mask[-1] = False\n    \n    submission_part = pd.DataFrame({\n        'video_id': meta_changes['video_id'][mask].values,\n        'agent_id': meta_changes['agent_id'][mask].values,\n        'target_id': meta_changes['target_id'][mask].values,\n        'action': pred.columns[ama_changes[mask].values],\n        'start_frame': ama_changes.index[mask],\n        'stop_frame': ama_changes.index[1:][mask[:-1]]\n    })\n    \n    stop_video_id = meta_changes['video_id'][1:][mask[:-1]].values\n    stop_agent_id = meta_changes['agent_id'][1:][mask[:-1]].values\n    stop_target_id = meta_changes['target_id'][1:][mask[:-1]].values\n    \n    for i in range(len(submission_part)):\n        video_id = submission_part.video_id.iloc[i]\n        agent_id = submission_part.agent_id.iloc[i]\n        target_id = submission_part.target_id.iloc[i]\n        if i < len(stop_video_id):\n            if stop_video_id[i] != video_id or stop_agent_id[i] != agent_id or stop_target_id[i] != target_id:\n                new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n                submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n        else:\n            new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n            submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n    \n    # Filter out very short events (likely noise)\n    duration = submission_part.stop_frame - submission_part.start_frame\n    submission_part = submission_part[duration >= 3].reset_index(drop=True)\n    \n    if len(submission_part) > 0:\n        assert (submission_part.stop_frame > submission_part.start_frame).all(), 'stop <= start'\n    \n    if verbose: print(f'  actions found: {len(submission_part)}')\n    return submission_part","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:28:25.650138Z","iopub.execute_input":"2025-11-10T09:28:25.650364Z","iopub.status.idle":"2025-11-10T09:28:25.659529Z","shell.execute_reply.started":"2025-11-10T09:28:25.650342Z","shell.execute_reply":"2025-11-10T09:28:25.658851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==================== ADVANCED FEATURE ENGINEERING (FPS-AWARE) ====================\n\ndef safe_rolling(series, window, func, min_periods=None):\n    \"\"\"Safe rolling operation with NaN handling\"\"\"\n    if min_periods is None:\n        min_periods = max(1, window // 4)\n    return series.rolling(window, min_periods=min_periods, center=True).apply(func, raw=True)\n\ndef _scale(n_frames_at_30fps, fps, ref=30.0):\n    \"\"\"Scale a frame count defined at 30 fps to the current video's fps.\"\"\"\n    return max(1, int(round(n_frames_at_30fps * float(fps) / ref)))\n\ndef _scale_signed(n_frames_at_30fps, fps, ref=30.0):\n    \"\"\"Signed version of _scale for forward/backward shifts (keeps at least 1 frame when |n|>=1).\"\"\"\n    if n_frames_at_30fps == 0:\n        return 0\n    s = 1 if n_frames_at_30fps > 0 else -1\n    mag = max(1, int(round(abs(n_frames_at_30fps) * float(fps) / ref)))\n    return s * mag\n\ndef _fps_from_meta(meta_df, fallback_lookup, default_fps=30.0):\n    if 'frames_per_second' in meta_df.columns and pd.notnull(meta_df['frames_per_second']).any():\n        return float(meta_df['frames_per_second'].iloc[0])\n    vid = meta_df['video_id'].iloc[0]\n    return float(fallback_lookup.get(vid, default_fps))\n\ndef _speed(cx: pd.Series, cy: pd.Series, fps: float) -> pd.Series:\n    return np.hypot(cx.diff(), cy.diff()).fillna(0.0) * float(fps)\n\ndef _roll_future_mean(s: pd.Series, w: int, min_p: int = 1) -> pd.Series:\n    # mean over [t, t+w-1]\n    return s.iloc[::-1].rolling(w, min_periods=min_p).mean().iloc[::-1]\n\ndef _roll_future_var(s: pd.Series, w: int, min_p: int = 2) -> pd.Series:\n    # var over [t, t+w-1]\n    return s.iloc[::-1].rolling(w, min_periods=min_p).var().iloc[::-1]\n\n\ndef add_curvature_features(X, center_x, center_y, fps):\n    \"\"\"Trajectory curvature (window lengths scaled by fps).\"\"\"\n    vel_x = center_x.diff()\n    vel_y = center_y.diff()\n    acc_x = vel_x.diff()\n    acc_y = vel_y.diff()\n\n    cross_prod = vel_x * acc_y - vel_y * acc_x\n    vel_mag = np.sqrt(vel_x**2 + vel_y**2)\n    curvature = np.abs(cross_prod) / (vel_mag**3 + 1e-6)  # invariant to time scaling\n\n    for w in [30, 60]:\n        ws = _scale(w, fps)\n        X[f'curv_mean_{w}'] = curvature.rolling(ws, min_periods=max(1, ws // 6)).mean()\n\n    angle = np.arctan2(vel_y, vel_x)\n    angle_change = np.abs(angle.diff())\n    w = 30\n    ws = _scale(w, fps)\n    X[f'turn_rate_{w}'] = angle_change.rolling(ws, min_periods=max(1, ws // 6)).sum()\n\n    return X\n\ndef add_multiscale_features(X, center_x, center_y, fps):\n    \"\"\"Multi-scale temporal features (speed in cm/s; windows scaled by fps).\"\"\"\n    # displacement per frame is already in cm (pix normalized earlier); convert to cm/s\n    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)\n\n    scales = [10, 40, 160]\n    for scale in scales:\n        ws = _scale(scale, fps)\n        if len(speed) >= ws:\n            X[f'sp_m{scale}'] = speed.rolling(ws, min_periods=max(1, ws // 4)).mean()\n            X[f'sp_s{scale}'] = speed.rolling(ws, min_periods=max(1, ws // 4)).std()\n\n    if len(scales) >= 2 and f'sp_m{scales[0]}' in X.columns and f'sp_m{scales[-1]}' in X.columns:\n        X['sp_ratio'] = X[f'sp_m{scales[0]}'] / (X[f'sp_m{scales[-1]}'] + 1e-6)\n\n    return X\n\ndef add_state_features(X, center_x, center_y, fps):\n    \"\"\"Behavioral state transitions; bins adjusted so semantics are fps-invariant.\"\"\"\n    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)  # cm/s\n    w_ma = _scale(15, fps)\n    speed_ma = speed.rolling(w_ma, min_periods=max(1, w_ma // 3)).mean()\n\n    try:\n        # Original bins (cm/frame): [-inf, 0.5, 2.0, 5.0, inf]\n        # Convert to cm/s by multiplying by fps to keep thresholds consistent across fps.\n        bins = [-np.inf, 0.5 * fps, 2.0 * fps, 5.0 * fps, np.inf]\n        speed_states = pd.cut(speed_ma, bins=bins, labels=[0, 1, 2, 3]).astype(float)\n\n        for window in [60, 120]:\n            ws = _scale(window, fps)\n            if len(speed_states) >= ws:\n                for state in [0, 1, 2, 3]:\n                    X[f's{state}_{window}'] = (\n                        (speed_states == state).astype(float)\n                        .rolling(ws, min_periods=max(1, ws // 6)).mean()\n                    )\n                state_changes = (speed_states != speed_states.shift(1)).astype(float)\n                X[f'trans_{window}'] = state_changes.rolling(ws, min_periods=max(1, ws // 6)).sum()\n    except Exception:\n        pass\n\n    return X\n\ndef add_longrange_features(\n    X,\n    center_x,\n    center_y,\n    fps,\n    long_windows: Optional[list] = None,\n    ewm_spans: Optional[list] = None,\n    pct_windows: Optional[list] = None\n):\n    \"\"\"\n    Long-range temporal features (windows & spans scaled by fps).\n    Parameters:\n      - X: DataFrame to append features to\n      - center_x, center_y: pd.Series of coordinates (in cm)\n      - fps: frames per second (float)\n      - long_windows: list of integer window bases (in frames @30fps) for long moving averages (default [120,240,480])\n      - ewm_spans: list of integer spans (in frames @30fps) for EWM (default [60,120,240])\n      - pct_windows: list of integer window bases for speed percentile ranking (default [60,120,240])\n    \"\"\"\n    if long_windows is None:\n        long_windows = [30, 60,120, 240, 480]\n    if ewm_spans is None:\n        ewm_spans = [15, 30,60, 120, 240]\n    if pct_windows is None:\n        pct_windows = [15, 30,60, 120, 240]\n\n    # long moving average of positions\n    for window in long_windows:\n        ws = _scale(window, fps)\n        if len(center_x) >= ws:\n            X[f'x_ml{window}'] = center_x.rolling(ws, min_periods=max(5, ws // 6)).mean()\n            X[f'y_ml{window}'] = center_y.rolling(ws, min_periods=max(5, ws // 6)).mean()\n\n    # EWM (span interpreted in frames)\n    for span in ewm_spans:\n        s = _scale(span, fps)\n        # pandas ewm accepts span as float/int; keep min_periods=1 to avoid excessive NaNs\n        X[f'x_e{span}'] = center_x.ewm(span=s, min_periods=1).mean()\n        X[f'y_e{span}'] = center_y.ewm(span=s, min_periods=1).mean()\n\n    # speed-based percentile rank over windows\n    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)  # cm/s\n    for window in pct_windows:\n        ws = _scale(window, fps)\n        if len(speed) >= ws:\n            X[f'sp_pct{window}'] = speed.rolling(ws, min_periods=max(5, ws // 6)).rank(pct=True)\n\n    return X\n\n\ndef add_cumulative_distance_single(X, cx, cy, fps, horizon_frames_base: int = 180, colname: str = \"path_cum180\"):\n    L = max(1, _scale(horizon_frames_base, fps))  # frames\n    # step length (cm per frame since coords are cm)\n    step = np.hypot(cx.diff(), cy.diff())\n    # centered rolling sum over ~2L+1 frames (acausal)\n    path = step.rolling(2*L + 1, min_periods=max(5, L//6), center=True).sum()\n    X[colname] = path.fillna(0.0).astype(np.float32)\n    return X\n\n\ndef add_groom_microfeatures(X, df, fps):\n    parts = df.columns.get_level_values(0)\n    if 'body_center' not in parts or 'nose' not in parts:\n        return X\n\n    cx = df['body_center']['x']; cy = df['body_center']['y']\n    nx = df['nose']['x']; ny = df['nose']['y']\n\n    cs = (np.sqrt(cx.diff()**2 + cy.diff()**2) * float(fps)).fillna(0)\n    ns = (np.sqrt(nx.diff()**2 + ny.diff()**2) * float(fps)).fillna(0)\n\n    w30 = _scale(30, fps)\n    X['head_body_decouple'] = (ns / (cs + 1e-3)).clip(0, 10).rolling(w30, min_periods=max(1, w30//3)).median()\n\n    r = np.sqrt((nx - cx)**2 + (ny - cy)**2)\n    X['nose_rad_std'] = r.rolling(w30, min_periods=max(1, w30//3)).std().fillna(0)\n\n    if 'tail_base' in parts:\n        ang = np.arctan2(df['nose']['y']-df['tail_base']['y'], df['nose']['x']-df['tail_base']['x'])\n        dang = np.abs(ang.diff()).fillna(0)\n        X['head_orient_jitter'] = dang.rolling(w30, min_periods=max(1, w30//3)).mean()\n\n    return X\n\n\ndef add_interaction_features(X, mouse_pair, avail_A, avail_B, fps):\n    \"\"\"Social interaction features (windows scaled by fps).\"\"\"\n    if 'body_center' not in avail_A or 'body_center' not in avail_B:\n        return X\n\n    rel_x = mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x']\n    rel_y = mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y']\n    rel_dist = np.sqrt(rel_x**2 + rel_y**2)\n\n    # per-frame velocities (cm/frame)\n    A_vx = mouse_pair['A']['body_center']['x'].diff()\n    A_vy = mouse_pair['A']['body_center']['y'].diff()\n    B_vx = mouse_pair['B']['body_center']['x'].diff()\n    B_vy = mouse_pair['B']['body_center']['y'].diff()\n\n    A_lead = (A_vx * rel_x + A_vy * rel_y) / (np.sqrt(A_vx**2 + A_vy**2) * rel_dist + 1e-6)\n    B_lead = (B_vx * (-rel_x) + B_vy * (-rel_y)) / (np.sqrt(B_vx**2 + B_vy**2) * rel_dist + 1e-6)\n\n    for window in [30, 60]:\n        ws = _scale(window, fps)\n        X[f'A_ld{window}'] = A_lead.rolling(ws, min_periods=max(1, ws // 6)).mean()\n        X[f'B_ld{window}'] = B_lead.rolling(ws, min_periods=max(1, ws // 6)).mean()\n\n    approach = -rel_dist.diff()  # decreasing distance => positive approach\n    chase = approach * B_lead\n    w = 30\n    ws = _scale(w, fps)\n    X[f'chase_{w}'] = chase.rolling(ws, min_periods=max(1, ws // 6)).mean()\n\n    for window in [60, 120]:\n        ws = _scale(window, fps)\n        A_sp = np.sqrt(A_vx**2 + A_vy**2)\n        B_sp = np.sqrt(B_vx**2 + B_vy**2)\n        X[f'sp_cor{window}'] = A_sp.rolling(ws, min_periods=max(1, ws // 6)).corr(B_sp)\n\n    return X\n\n# ===============================================================\n# 1) Past–vs–Future speed asymmetry (acausal, continuous)\n#    Δv = mean_future(speed) - mean_past(speed)\n# ===============================================================\ndef add_speed_asymmetry_future_past_single(\n    X: pd.DataFrame, cx: pd.Series, cy: pd.Series, fps: float,\n    horizon_base: int = 30, agg: str = \"mean\"\n) -> pd.DataFrame:\n    w = max(3, _scale(horizon_base, fps))\n    v = _speed(cx, cy, fps)\n    if agg == \"median\":\n        v_past = v.rolling(w, min_periods=max(3, w//4), center=False).median()\n        v_fut  = v.iloc[::-1].rolling(w, min_periods=max(3, w//4)).median().iloc[::-1]\n    else:\n        v_past = v.rolling(w, min_periods=max(3, w//4), center=False).mean()\n        v_fut  = _roll_future_mean(v, w, min_p=max(3, w//4))\n    X[\"spd_asym_1s\"] = (v_fut - v_past).fillna(0.0)\n    return X\n\n# ===============================================================\n# 2) Distribution shift (future vs past) via symmetric KL of\n#    Gaussian fits on speed \n# ===============================================================\ndef add_gauss_shift_speed_future_past_single(\n    X: pd.DataFrame, cx: pd.Series, cy: pd.Series, fps: float,\n    window_base: int = 30, eps: float = 1e-6\n) -> pd.DataFrame:\n    w = max(5, _scale(window_base, fps))\n    v = _speed(cx, cy, fps)\n\n    mu_p = v.rolling(w, min_periods=max(3, w//4)).mean()\n    va_p = v.rolling(w, min_periods=max(3, w//4)).var().clip(lower=eps)\n\n    mu_f = _roll_future_mean(v, w, min_p=max(3, w//4))\n    va_f = _roll_future_var(v, w, min_p=max(3, w//4)).clip(lower=eps)\n\n    # KL(Np||Nf) + KL(Nf||Np)\n    kl_pf = 0.5 * ((va_p/va_f) + ((mu_f - mu_p)**2)/va_f - 1.0 + np.log(va_f/va_p))\n    kl_fp = 0.5 * ((va_f/va_p) + ((mu_p - mu_f)**2)/va_p - 1.0 + np.log(va_p/va_f))\n    X[\"spd_symkl_1s\"] = (kl_pf + kl_fp).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n    return X\n\ndef add_segmental_features_single(\n    X: pd.DataFrame, cx: pd.Series, cy: pd.Series, fps: float,\n    horizons_base=(30, 90), pause_thr_cms: float = 2.0\n) -> pd.DataFrame:\n    \"\"\"Segment-level trend/acc/jerk/pause over ~1s/3s windows (fps-aware).\"\"\"\n    v = _speed(cx, cy, fps)\n    acc = v.diff() * float(fps)\n    jerk = acc.diff() * float(fps)\n\n    for h in horizons_base:\n        w = max(3, _scale(h, fps))\n        min_p = max(3, w // 3)\n\n        def _slope(arr):\n            arr = arr[np.isfinite(arr)]\n            L = len(arr)\n            if L < 2:\n                return 0.0\n            idx = np.arange(L, dtype=np.float32)\n            sum_x = float(idx.sum())\n            sum_x2 = float((idx * idx).sum())\n            denom = L * sum_x2 - sum_x * sum_x\n            if denom == 0:\n                return 0.0\n            sum_y = float(arr.sum())\n            sum_xy = float((idx * arr).sum())\n            return (L * sum_xy - sum_x * sum_y) / denom\n\n        X[f'sp_sl_{h}'] = v.rolling(w, center=True, min_periods=min_p).apply(_slope, raw=True)\n        X[f'acc_m_{h}'] = acc.rolling(w, center=True, min_periods=min_p).mean()\n        X[f'acc_v_{h}'] = acc.rolling(w, center=True, min_periods=min_p).var()\n        X[f'jerk_m_{h}'] = jerk.rolling(w, center=True, min_periods=min_p).mean()\n        X[f'pause_r_{h}'] = (v < pause_thr_cms).rolling(w, center=True, min_periods=1).mean()\n\n    return X\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:28:25.660452Z","iopub.execute_input":"2025-11-10T09:28:25.661037Z","iopub.status.idle":"2025-11-10T09:28:25.694175Z","shell.execute_reply.started":"2025-11-10T09:28:25.661014Z","shell.execute_reply":"2025-11-10T09:28:25.693369Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def transform_single(single_mouse, body_parts_tracked, fps):\n    \"\"\"Enhanced single mouse transform (FPS-aware windows/lags; distances in cm).\"\"\"\n    available_body_parts = single_mouse.columns.get_level_values(0)\n\n    # Base distance features (squared distances across body parts)\n    X = pd.DataFrame({\n        f\"{p1}+{p2}\": np.square(single_mouse[p1] - single_mouse[p2]).sum(axis=1, skipna=False)\n        for p1, p2 in itertools.combinations(body_parts_tracked, 2)\n        if p1 in available_body_parts and p2 in available_body_parts\n    })\n    X = X.reindex(columns=[f\"{p1}+{p2}\" for p1, p2 in itertools.combinations(body_parts_tracked, 2)], copy=False)\n\n    # Speed-like features via lagged displacements (duration-aware lag)\n    if all(p in single_mouse.columns for p in ['ear_left', 'ear_right', 'tail_base']):\n        speed_lags = [1,2,3,4,5, 10, 20, 30,40,50,60]\n        speed_parts = []\n        for lag_base in speed_lags:\n            lag = _scale(lag_base, fps)\n            shifted = single_mouse[['ear_left', 'ear_right', 'tail_base']].shift(lag)\n            suf = f\"l{lag_base}\"\n            speed_parts.append(pd.DataFrame({\n                f'sp_lf_{suf}': np.square(single_mouse['ear_left'] - shifted['ear_left']).sum(axis=1, skipna=False),\n                f'sp_rt_{suf}': np.square(single_mouse['ear_right'] - shifted['ear_right']).sum(axis=1, skipna=False),\n                f'sp_lf2_{suf}': np.square(single_mouse['ear_left'] - shifted['tail_base']).sum(axis=1, skipna=False),\n                f'sp_rt2_{suf}': np.square(single_mouse['ear_right'] - shifted['tail_base']).sum(axis=1, skipna=False),\n            }))\n\n        speeds = pd.concat(speed_parts, axis=1)\n        # Keep original names for backward compatibility (based on 10-frame base lag)\n        if 'sp_lf_l10' in speeds:\n            speeds = speeds.assign(\n                sp_lf=speeds['sp_lf_l10'],\n                sp_rt=speeds['sp_rt_l10'],\n                sp_lf2=speeds['sp_lf2_l10'],\n                sp_rt2=speeds['sp_rt2_l10'],\n            )\n        X = pd.concat([X, speeds], axis=1)\n\n    if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n        X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n\n    # Body angle (orientation)\n    if all(p in available_body_parts for p in ['nose', 'body_center', 'tail_base']):\n        v1 = single_mouse['nose'] - single_mouse['body_center']\n        v2 = single_mouse['tail_base'] - single_mouse['body_center']\n        X['body_ang'] = (v1['x'] * v2['x'] + v1['y'] * v2['y']) / (\n            np.sqrt(v1['x']**2 + v1['y']**2) * np.sqrt(v2['x']**2 + v2['y']**2) + 1e-6)\n\n    # Core temporal features (windows scaled by fps)\n    if 'body_center' in available_body_parts:\n        cx = single_mouse['body_center']['x']\n        cy = single_mouse['body_center']['y']\n\n        for w in [5, 15, 30, 60]:\n            ws = _scale(w, fps)\n            roll = dict(min_periods=1, center=True)\n            X[f'cx_m{w}'] = cx.rolling(ws, **roll).mean()\n            X[f'cy_m{w}'] = cy.rolling(ws, **roll).mean()\n            X[f'cx_s{w}'] = cx.rolling(ws, **roll).std()\n            X[f'cy_s{w}'] = cy.rolling(ws, **roll).std()\n            X[f'x_rng{w}'] = cx.rolling(ws, **roll).max() - cx.rolling(ws, **roll).min()\n            X[f'y_rng{w}'] = cy.rolling(ws, **roll).max() - cy.rolling(ws, **roll).min()\n            X[f'disp{w}'] = np.sqrt(cx.diff().rolling(ws, min_periods=1).sum()**2 +\n                                     cy.diff().rolling(ws, min_periods=1).sum()**2)\n            X[f'act{w}'] = np.sqrt(cx.diff().rolling(ws, min_periods=1).var() +\n                                   cy.diff().rolling(ws, min_periods=1).var())\n\n        # Advanced features (fps-scaled)\n        X = add_curvature_features(X, cx, cy, fps)\n        X = add_multiscale_features(X, cx, cy, fps)\n        X = add_state_features(X, cx, cy, fps)\n        X = add_longrange_features(X, cx, cy, fps)\n        X = add_cumulative_distance_single(X, cx, cy, fps, horizon_frames_base=180)\n        X = add_groom_microfeatures(X, single_mouse, fps)\n        X = add_speed_asymmetry_future_past_single(X, cx, cy, fps, horizon_base=30)         \n        X = add_gauss_shift_speed_future_past_single(X, cx, cy, fps, window_base=30)\n        X = add_segmental_features_single(X, cx, cy, fps, horizons_base=(30, 90))\n  \n    # Nose-tail features with duration-aware lags\n    if all(p in available_body_parts for p in ['nose', 'tail_base']):\n        nt_dist = np.sqrt((single_mouse['nose']['x'] - single_mouse['tail_base']['x'])**2 +\n                          (single_mouse['nose']['y'] - single_mouse['tail_base']['y'])**2)\n        for lag in [10, 20, 40]:\n            l = _scale(lag, fps)\n            X[f'nt_lg{lag}'] = nt_dist.shift(l)\n            X[f'nt_df{lag}'] = nt_dist - nt_dist.shift(l)\n\n    # Ear features with duration-aware offsets\n    if all(p in available_body_parts for p in ['ear_left', 'ear_right']):\n        ear_d = np.sqrt((single_mouse['ear_left']['x'] - single_mouse['ear_right']['x'])**2 +\n                        (single_mouse['ear_left']['y'] - single_mouse['ear_right']['y'])**2)\n        for off in [-20, -10, 10, 20]:\n            o = _scale_signed(off, fps)\n            X[f'ear_o{off}'] = ear_d.shift(-o)  \n        w = _scale(30, fps)\n        X['ear_con'] = ear_d.rolling(w, min_periods=1, center=True).std() / \\\n                       (ear_d.rolling(w, min_periods=1, center=True).mean() + 1e-6)\n\n    return X.astype(np.float32, copy=False)\n\ndef transform_pair(mouse_pair, body_parts_tracked, fps):\n    \"\"\"Enhanced pair transform (FPS-aware windows/lags; distances in cm).\"\"\"\n    avail_A = mouse_pair['A'].columns.get_level_values(0)\n    avail_B = mouse_pair['B'].columns.get_level_values(0)\n\n    # Inter-mouse distances (squared distances across all part pairs)\n    X = pd.DataFrame({\n        f\"12+{p1}+{p2}\": np.square(mouse_pair['A'][p1] - mouse_pair['B'][p2]).sum(axis=1, skipna=False)\n        for p1, p2 in itertools.product(body_parts_tracked, repeat=2)\n        if p1 in avail_A and p2 in avail_B\n    })\n    X = X.reindex(columns=[f\"12+{p1}+{p2}\" for p1, p2 in itertools.product(body_parts_tracked, repeat=2)], copy=False)\n\n    # Speed-like features via lagged displacements (duration-aware lag)\n    if ('A', 'ear_left') in mouse_pair.columns and ('B', 'ear_left') in mouse_pair.columns:\n        speed_lags = [5, 10, 20, 30]\n        speed_parts = []\n        for lag_base in speed_lags:\n            lag = _scale(lag_base, fps)\n            shA = mouse_pair['A']['ear_left'].shift(lag)\n            shB = mouse_pair['B']['ear_left'].shift(lag)\n            suf = f\"l{lag_base}\"\n            speed_parts.append(pd.DataFrame({\n                f'sp_A_{suf}': np.square(mouse_pair['A']['ear_left'] - shA).sum(axis=1, skipna=False),\n                f'sp_AB_{suf}': np.square(mouse_pair['A']['ear_left'] - shB).sum(axis=1, skipna=False),\n                f'sp_B_{suf}': np.square(mouse_pair['B']['ear_left'] - shB).sum(axis=1, skipna=False),\n            }))\n\n        speeds = pd.concat(speed_parts, axis=1)\n        if 'sp_A_l10' in speeds:\n            speeds = speeds.assign(\n                sp_A=speeds['sp_A_l10'],\n                sp_AB=speeds['sp_AB_l10'],\n                sp_B=speeds['sp_B_l10'],\n            )\n        X = pd.concat([X, speeds], axis=1)\n\n    if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n        X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n\n    # Relative orientation\n    if all(p in avail_A for p in ['nose', 'tail_base', 'body_center']) and all(p in avail_B for p in ['nose', 'tail_base', 'body_center']):\n        dir_A = mouse_pair['A']['nose'] - mouse_pair['A']['tail_base']\n        dir_B = mouse_pair['B']['nose'] - mouse_pair['B']['tail_base']\n        X['rel_ori'] = (dir_A['x'] * dir_B['x'] + dir_A['y'] * dir_B['y']) / (\n            np.sqrt(dir_A['x']**2 + dir_A['y']**2) * np.sqrt(dir_B['x']**2 + dir_B['y']**2) + 1e-6)\n        # Head-to-head alignment (parallel vs antiparallel vs orthogonal)\n        head_dot = (dir_A['x'] * dir_B['x'] + dir_A['y'] * dir_B['y'])\n        head_den = (np.sqrt(dir_A['x']**2 + dir_A['y']**2) * np.sqrt(dir_B['x']**2 + dir_B['y']**2) + 1e-6)\n        head_cos = head_dot / head_den\n        X['head_cos'] = head_cos\n        X['head_parallel'] = (head_cos > 0.5).astype(float)\n        X['head_antipar'] = (head_cos < -0.5).astype(float)\n        X['head_side'] = ((head_cos >= -0.5) & (head_cos <= 0.5)).astype(float)\n\n        def _ang(dx, dy):\n            return np.arctan2(dy, dx)\n\n        # Nose pointing to opponent body_center (facing vs back/side)\n        ang_A_head = _ang(dir_A['x'], dir_A['y'])\n        ang_B_head = _ang(dir_B['x'], dir_B['y'])\n        ang_A_to_Bc = _ang(mouse_pair['B']['body_center']['x'] - mouse_pair['A']['nose']['x'],\n                           mouse_pair['B']['body_center']['y'] - mouse_pair['A']['nose']['y'])\n        ang_B_to_Ac = _ang(mouse_pair['A']['body_center']['x'] - mouse_pair['B']['nose']['x'],\n                           mouse_pair['A']['body_center']['y'] - mouse_pair['B']['nose']['y'])\n\n        def _wrap_diff(a, b):\n            d = a - b\n            return np.arctan2(np.sin(d), np.cos(d))\n\n        ang_A_diff = _wrap_diff(ang_A_to_Bc, ang_A_head)\n        ang_B_diff = _wrap_diff(ang_B_to_Ac, ang_B_head)\n\n        X['A_face_cos'] = np.cos(ang_A_diff)\n        X['B_face_cos'] = np.cos(ang_B_diff)\n\n        # Facing bins (one-hot-ish)\n        X['A_face_front'] = (X['A_face_cos'] > 0.7).astype(float)\n        X['A_face_back']  = (X['A_face_cos'] < -0.5).astype(float)\n        X['A_face_side']  = ((X['A_face_cos'] <= 0.7) & (X['A_face_cos'] >= -0.5)).astype(float)\n        X['B_face_front'] = (X['B_face_cos'] > 0.7).astype(float)\n        X['B_face_back']  = (X['B_face_cos'] < -0.5).astype(float)\n        X['B_face_side']  = ((X['B_face_cos'] <= 0.7) & (X['B_face_cos'] >= -0.5)).astype(float)\n\n        # Ear-to-opponent-nose wedge: captures side-on vs face-on\n        if all(p in avail_A for p in ['ear_left', 'ear_right']) and 'nose' in avail_B:\n            ang_el = _ang(mouse_pair['B']['nose']['x'] - mouse_pair['A']['ear_left']['x'],\n                          mouse_pair['B']['nose']['y'] - mouse_pair['A']['ear_left']['y'])\n            ang_er = _ang(mouse_pair['B']['nose']['x'] - mouse_pair['A']['ear_right']['x'],\n                          mouse_pair['B']['nose']['y'] - mouse_pair['A']['ear_right']['y'])\n            X['A_ear_wedge'] = np.abs(_wrap_diff(ang_el, ang_er))\n        if all(p in avail_B for p in ['ear_left', 'ear_right']) and 'nose' in avail_A:\n            ang_el = _ang(mouse_pair['A']['nose']['x'] - mouse_pair['B']['ear_left']['x'],\n                          mouse_pair['A']['nose']['y'] - mouse_pair['B']['ear_left']['y'])\n            ang_er = _ang(mouse_pair['A']['nose']['x'] - mouse_pair['B']['ear_right']['x'],\n                          mouse_pair['A']['nose']['y'] - mouse_pair['B']['ear_right']['y'])\n            X['B_ear_wedge'] = np.abs(_wrap_diff(ang_el, ang_er))\n\n    # Approach rate (duration-aware lag)\n    if all(p in avail_A for p in ['nose']) and all(p in avail_B for p in ['nose']):\n        cur = np.square(mouse_pair['A']['nose'] - mouse_pair['B']['nose']).sum(axis=1, skipna=False)\n        lag = _scale(10, fps)\n        shA_n = mouse_pair['A']['nose'].shift(lag)\n        shB_n = mouse_pair['B']['nose'].shift(lag)\n        past = np.square(shA_n - shB_n).sum(axis=1, skipna=False)\n        X['appr'] = cur - past\n\n    # Distance bins (cm; unchanged by fps)\n    if 'body_center' in avail_A and 'body_center' in avail_B:\n        cd = np.sqrt((mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x'])**2 +\n                     (mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y'])**2)\n        X['v_cls'] = (cd < 5.0).astype(float)\n        X['cls']   = ((cd >= 5.0) & (cd < 15.0)).astype(float)\n        X['med']   = ((cd >= 15.0) & (cd < 30.0)).astype(float)\n        X['far']   = (cd >= 30.0).astype(float)\n\n    # Temporal interaction features (fps-adjusted windows)\n    if 'body_center' in avail_A and 'body_center' in avail_B:\n        cd_full = np.square(mouse_pair['A']['body_center'] - mouse_pair['B']['body_center']).sum(axis=1, skipna=False)\n\n        for w in [5, 15, 30, 60]:\n            ws = _scale(w, fps)\n            roll = dict(min_periods=1, center=True)\n            X[f'd_m{w}']  = cd_full.rolling(ws, **roll).mean()\n            X[f'd_s{w}']  = cd_full.rolling(ws, **roll).std()\n            X[f'd_mn{w}'] = cd_full.rolling(ws, **roll).min()\n            X[f'd_mx{w}'] = cd_full.rolling(ws, **roll).max()\n\n            d_var = cd_full.rolling(ws, **roll).var()\n            X[f'int{w}'] = 1 / (1 + d_var)\n\n            Axd = mouse_pair['A']['body_center']['x'].diff()\n            Ayd = mouse_pair['A']['body_center']['y'].diff()\n            Bxd = mouse_pair['B']['body_center']['x'].diff()\n            Byd = mouse_pair['B']['body_center']['y'].diff()\n            coord = Axd * Bxd + Ayd * Byd\n            X[f'co_m{w}'] = coord.rolling(ws, **roll).mean()\n            X[f'co_s{w}'] = coord.rolling(ws, **roll).std()\n\n    # Nose-nose dynamics (duration-aware lags)\n    if 'nose' in avail_A and 'nose' in avail_B:\n        nn = np.sqrt((mouse_pair['A']['nose']['x'] - mouse_pair['B']['nose']['x'])**2 +\n                     (mouse_pair['A']['nose']['y'] - mouse_pair['B']['nose']['y'])**2)\n        for lag in [1,2,3,4,5,6,7,8,9,10, 20, 30, 40, 50, 60, 70,80,90,100]:\n            l = _scale(lag, fps)\n            X[f'nn_lg{lag}']  = nn.shift(l)\n            X[f'nn_ch{lag}']  = nn - nn.shift(l)\n            is_cl = (nn < 10.0).astype(float)\n            X[f'cl_ps{lag}']  = is_cl.rolling(l, min_periods=1).mean()\n            \n        # Nose approach vs lateral slip (cm/s; >0 means separating along radial line)\n        rel_x = mouse_pair['A']['nose']['x'] - mouse_pair['B']['nose']['x']\n        rel_y = mouse_pair['A']['nose']['y'] - mouse_pair['B']['nose']['y']\n        Avx = mouse_pair['A']['nose']['x'].diff()\n        Avy = mouse_pair['A']['nose']['y'].diff()\n        Bvx = mouse_pair['B']['nose']['x'].diff()\n        Bvy = mouse_pair['B']['nose']['y'].diff()\n        rel_den = (nn + 1e-6)\n        rv = ((Avx - Bvx) * rel_x + (Avy - Bvy) * rel_y) / rel_den\n        lv = ((Avx - Bvx) * (-rel_y) + (Avy - Bvy) * rel_x) / rel_den\n        X['nn_rad_sp'] = (rv * float(fps)).fillna(0)\n        X['nn_lat_sp'] = (lv * float(fps)).fillna(0)\n\n        # Nose speeds and imbalance (cm/s)\n        A_sp = np.sqrt(Avx**2 + Avy**2) * float(fps)\n        B_sp = np.sqrt(Bvx**2 + Bvy**2) * float(fps)\n        gap_sp = (A_sp - B_sp)\n        X['nose_spdA'] = A_sp\n        X['nose_spdB'] = B_sp\n        X['nose_spd_gap'] = gap_sp\n        for lag in [5, 10, 20, 30]:\n            l = _scale(lag, fps)\n            X[f'nose_spdA_lg{lag}'] = A_sp.shift(l)\n            X[f'nose_spdB_lg{lag}'] = B_sp.shift(l)\n            X[f'nose_spd_gap_lg{lag}'] = gap_sp.shift(l)\n\n        # Rolling proximity stats and multi-threshold contact ratios\n        roll_opts = dict(min_periods=1, center=True)\n        for w in [5, 15, 45]:\n            ws = _scale(w, fps)\n            X[f'nn_mean{w}'] = nn.rolling(ws, **roll_opts).mean()\n            X[f'nn_std{w}']  = nn.rolling(ws, **roll_opts).std()\n            for thr in (8.0, 12.0, 15.0):\n                X[f'nn_ct{int(thr)}_{w}'] = (nn < thr).rolling(ws, **roll_opts).mean()\n\n\n    # Velocity alignment (duration-aware offsets)\n    if 'body_center' in avail_A and 'body_center' in avail_B:\n        Avx = mouse_pair['A']['body_center']['x'].diff()\n        Avy = mouse_pair['A']['body_center']['y'].diff()\n        Bvx = mouse_pair['B']['body_center']['x'].diff()\n        Bvy = mouse_pair['B']['body_center']['y'].diff()\n        val = (Avx * Bvx + Avy * Bvy) / (np.sqrt(Avx**2 + Avy**2) * np.sqrt(Bvx**2 + Bvy**2) + 1e-6)\n\n        for off in [-20, -10, 10, 20]:\n            o = _scale_signed(off, fps)\n            X[f'va_{off}'] = val.shift(-o)\n\n        w = _scale(30, fps)\n        X['int_con'] = cd_full.rolling(w, min_periods=1, center=True).std() / \\\n                       (cd_full.rolling(w, min_periods=1, center=True).mean() + 1e-6)\n\n        # Advanced interaction (fps-adjusted internals)\n        X = add_interaction_features(X, mouse_pair, avail_A, avail_B, fps)\n        \n\n    return X.astype(np.float32, copy=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:28:25.694853Z","iopub.execute_input":"2025-11-10T09:28:25.695054Z","iopub.status.idle":"2025-11-10T09:28:25.725638Z","shell.execute_reply.started":"2025-11-10T09:28:25.695039Z","shell.execute_reply":"2025-11-10T09:28:25.724954Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tune_threshold(oof_pred: np.ndarray, y_true: np.ndarray) -> float:\n    \"\"\"Search the probability cutoff that maximizes F1.\"\"\"\n    def objective(trial):\n        threshold = trial.suggest_float(\"threshold\", 0.0, 1.0, step=0.01)\n        return f1_score(y_true, (oof_pred >= threshold), zero_division=0)\n\n    # Silence per-trial Optuna INFO logs; only report when we get a better score.\n    optuna.logging.set_verbosity(optuna.logging.WARNING)\n    best_val = [-np.inf]\n\n    def _report_best(study, trial):\n        if trial.value is None:\n            return\n        if trial.value > best_val[0]:\n            best_val[0] = trial.value\n            if verbose:\n                print(f\"  [tune] trial={trial.number} new best thr={trial.params['threshold']:.2f} f1={trial.value:.4f}\")\n\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=200, n_jobs=-1, callbacks=[_report_best])\n    return float(study.best_params[\"threshold\"])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def submit_ensemble(body_parts_tracked_str, switch_tr, X_tr, label, meta, n_samples=1_500_000):\n    slug = _slugify(body_parts_tracked_str)\n    thr_dir = THRESHOLD_DIR\n    mdl_dir = MODEL_DIR\n    thr_load_dir = THRESHOLD_LOAD_DIR\n    mdl_load_dir = MODEL_LOAD_DIR\n    os.makedirs(thr_dir, exist_ok=True)\n    os.makedirs(mdl_dir, exist_ok=True)\n    thr_path = os.path.join(thr_dir, f\"{slug}_{switch_tr}_thresholds.pkl\")\n    mdl_path = os.path.join(mdl_dir, f\"{slug}_{switch_tr}_models.pkl\")\n    thr_load_path = os.path.join(thr_load_dir, f\"{slug}_{switch_tr}_thresholds.pkl\")\n    mdl_load_path = os.path.join(mdl_load_dir, f\"{slug}_{switch_tr}_models.pkl\")\n\n    models = []\n    xgb0 = _make_xgb(\n        n_estimators=180, learning_rate=0.08, max_depth=6,\n        min_child_weight=8 if USE_GPU else 5, gamma=1.0 if USE_GPU else 0.,\n        subsample=0.8, colsample_bytree=0.8, single_precision_histogram=USE_GPU,\n        verbosity=0\n    )\n    models.append(make_pipeline(StratifiedSubsetClassifier(xgb0, n_samples and int(n_samples/1.2))))\n\n    xgb_250 = _make_xgb(\n        n_estimators=250, learning_rate=0.08, max_depth=6,\n        min_child_weight=8 if USE_GPU else 5, gamma=1.0 if USE_GPU else 0.,\n        subsample=0.8, colsample_bytree=0.8, single_precision_histogram=USE_GPU,\n        verbosity=0\n    )\n    models.append(make_pipeline(StratifiedSubsetClassifier(xgb_250, n_samples and int(n_samples/1.2))))\n\n    model_names = ['xgb_180','xgb_250']\n\n    if USE_GPU:\n        # GPU-only heavy XGBs etc (same as before)\n        xgb1 = XGBClassifier(\n            random_state=SEED, booster=\"gbtree\", tree_method=\"gpu_hist\",\n            n_estimators=2000, learning_rate=0.05, grow_policy=\"lossguide\",\n            max_leaves=255, max_depth=0, min_child_weight=10, gamma=0.0,\n            subsample=0.90, colsample_bytree=1.00, colsample_bylevel=0.85,\n            reg_alpha=0.0, reg_lambda=1.0, max_bin=256,\n            single_precision_histogram=True, verbosity=0\n        )\n        models.append(make_pipeline(\n            StratifiedSubsetClassifierWEval(xgb1, n_samples and int(n_samples/2.),\n                                            random_state=SEED, valid_size=0.10, val_cap_ratio=0.25,\n                                            es_rounds=\"auto\", es_metric=\"auto\")\n        ))\n        xgb2 = XGBClassifier(\n            random_state=SEED, booster=\"gbtree\", tree_method=\"gpu_hist\",\n            n_estimators=1400, learning_rate=0.06, max_depth=7,\n            min_child_weight=12, subsample=0.70, colsample_bytree=0.80,\n            reg_alpha=0.0, reg_lambda=1.5, max_bin=256,\n            single_precision_histogram=True, verbosity=0\n        )\n        models.append(make_pipeline(\n            StratifiedSubsetClassifierWEval(xgb2, n_samples and int(n_samples/1.5),\n                                            random_state=SEED, valid_size=0.10, val_cap_ratio=0.25,\n                                            es_rounds=\"auto\", es_metric=\"auto\")\n        ))\n        model_names.extend(['xgb1', 'xgb2'])\n\n    action_thresholds = defaultdict(lambda: 0.27)\n    model_list = []\n\n    # ---------- thresholds ----------\n    if not USE_ADAPTIVE_THRESHOLDS:\n        if verbose:\n            print(f\"[thr] using fixed threshold 0.27 | {switch_tr}\")\n    elif LOAD_THRESHOLDS and os.path.exists(thr_load_path):\n        loaded_thr = joblib.load(thr_load_path)\n        action_thresholds.update(loaded_thr)\n        if verbose:\n            print(f\"[thr] loaded thresholds from {thr_load_path}\")\n    else:\n        for action in label.columns:\n            action_mask = ~label[action].isna().values\n            y_action = label[action][action_mask].values.astype(int)\n            meta_masked = meta.iloc[action_mask]\n            groups_action = meta_masked.video_id.values\n\n            tune_cap = n_samples\n            X_action = X_tr[action_mask]\n            X_tune = X_action\n            y_tune = y_action\n            groups_tune = groups_action\n            if len(y_tune) > tune_cap:\n                rng = np.random.default_rng(SEED)\n                keep_idx = rng.choice(len(y_tune), size=tune_cap, replace=False)\n                X_tune = X_action.iloc[keep_idx]\n                y_tune = y_action[keep_idx]\n                groups_tune = groups_action[keep_idx]\n\n            unique_groups = np.unique(groups_tune)\n            n_pos = int(y_tune.sum())\n            n_neg = int(len(y_tune) - n_pos)\n            if len(unique_groups) >= 2 and n_pos > 0 and n_neg > 0:\n                n_splits = min(5, len(unique_groups))\n                cv_raw = GroupKFold(n_splits=n_splits)\n                splits = list(cv_raw.split(np.zeros(len(y_tune), dtype=np.int8), y_tune, groups_tune))\n\n                single_class_fold = any(\n                    (np.unique(y_tune[tr_idx]).size < 2) or (np.unique(y_tune[te_idx]).size < 2)\n                    for tr_idx, te_idx in splits\n                )\n                if single_class_fold:\n                    if verbose:\n                        print(f\"threshold tuning skipped (single-class fold) | {switch_tr} | action={action}\")\n                else:\n                    base_model = clone(models[0])\n                    oof_pred = cross_val_predict(\n                        base_model,\n                        X_tune,\n                        y_tune,\n                        cv=splits,\n                        groups=groups_tune,\n                        method=\"predict_proba\",\n                        n_jobs=1\n                    )[:, 1]\n                    tuned_thr = tune_threshold(oof_pred, y_tune)\n                    action_thresholds[action] = tuned_thr\n                    if verbose:\n                        print(f\"tuned threshold {tuned_thr:.2f} | {switch_tr} | action={action} | groups={len(unique_groups)}\")\n                    del base_model, oof_pred, splits\n                    gc.collect()\n            else:\n                if verbose:\n                    print(f\"threshold tuning skipped (insufficient groups or classes) | {switch_tr} | action={action}\")\n\n    try:\n        joblib.dump(dict(action_thresholds), thr_path)\n        if verbose:\n            print(f\"saved thresholds -> {thr_path}\")\n    except OSError as e:\n        if verbose:\n            print(f\"[thr] save failed ({e}); skipping save.\")\n\n    if ONLY_TUNE_THRESHOLDS:\n        if verbose:\n            print(\"[mode] ONLY_TUNE_THRESHOLDS=True, skipping training and inference.\")\n        del X_tr; gc.collect()\n        return\n\n    # ---------- models ----------\n    if LOAD_MODELS and os.path.exists(mdl_load_path):\n        model_list = joblib.load(mdl_load_path)\n        if verbose:\n            print(f\"[mdl] loaded models from {mdl_load_path}\")\n        if CHECK_LOAD:\n            # Drop loaded actions that have no positives in current data\n            filtered = []\n            for action, trained in model_list:\n                action_mask = ~label[action].isna().values\n                y_action = label[action][action_mask].values.astype(int)\n                if y_action.sum() == 0:\n                    if verbose:\n                        print(f\"[mdl] drop loaded action={action} (no positives in current data)\")\n                    continue\n                filtered.append((action, trained))\n            model_list = filtered\n    else:\n        for action in label.columns:\n            action_mask = ~label[action].isna().values\n            y_action = label[action][action_mask].values.astype(int)\n            meta_masked = meta.iloc[action_mask]\n            groups_action = meta_masked.video_id.values\n            if y_action.sum() == 0:\n                if verbose:\n                    print(f\"[mdl] skip action={action} (no positives)\")\n                continue\n\n            trained = []\n            for model_idx, m in enumerate(models):\n                m_clone = clone(m)\n                t0 = perf_counter()\n                m_clone.fit(X_tr[action_mask], y_action)\n                dt = perf_counter() - t0\n                print(f\"trained model {model_names[model_idx]} | {switch_tr} | action={action} | {dt:.1f}s\", flush=True)\n                trained.append(m_clone)\n\n            if trained:\n                model_list.append((action, trained))\n\n        try:\n            joblib.dump(model_list, mdl_path)\n            if verbose:\n                print(f\"saved models -> {mdl_path}\")\n        except OSError as e:\n            if verbose:\n                print(f\"[mdl] save failed ({e}); skipping save.\")\n\n    del X_tr; gc.collect()\n\n    # ---- TEST INFERENCE ----\n    body_parts_tracked = json.loads(body_parts_tracked_str)\n    if len(body_parts_tracked) > 5:\n        body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n\n    test_subset = test[test.body_parts_tracked == body_parts_tracked_str]\n    generator = generate_mouse_data(\n        test_subset, 'test',\n        generate_single=(switch_tr == 'single'),\n        generate_pair=(switch_tr == 'pair')\n    )\n    fps_lookup = (test_subset[['video_id','frames_per_second']]\n                    .drop_duplicates('video_id')\n                    .set_index('video_id')['frames_per_second'].to_dict())\n\n    for switch_te, data_te, meta_te, actions_te in generator:\n        assert switch_te == switch_tr\n        try:\n            fps_i = _fps_from_meta(meta_te, fps_lookup, default_fps=30.0)\n            if switch_te == 'single':\n                X_te = transform_single(data_te, body_parts_tracked, fps_i)\n            else:\n                X_te = transform_pair(data_te, body_parts_tracked, fps_i)\n\n            del data_te\n\n            pred = pd.DataFrame(index=meta_te.video_frame)\n            for action, trained in model_list:\n                if action in actions_te:\n                    probs = []\n                    for mi, mdl in enumerate(trained):\n                        probs.append(mdl.predict_proba(X_te)[:, 1])\n                    pred[action] = np.mean(probs, axis=0)\n\n            del X_te; gc.collect()\n\n            if pred.shape[1] != 0:\n                submission_list.append(predict_multiclass_adaptive(pred, meta_te, action_thresholds))\n        except Exception as e:\n            print(e)\n            try: del data_te\n            except: pass\n            gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:28:25.743965Z","iopub.execute_input":"2025-11-10T09:28:25.744127Z","iopub.status.idle":"2025-11-10T09:28:25.762133Z","shell.execute_reply.started":"2025-11-10T09:28:25.744114Z","shell.execute_reply":"2025-11-10T09:28:25.761535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def robustify(submission, dataset, traintest, traintest_directory=None):\n    if traintest_directory is None:\n        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n\n    submission = submission[submission.start_frame < submission.stop_frame]\n\n    group_list = []\n    for _, group in submission.groupby(['video_id', 'agent_id', 'target_id']):\n        group = group.sort_values('start_frame')\n        mask = np.ones(len(group), dtype=bool)\n        last_stop = 0\n        for i, (_, row) in enumerate(group.iterrows()):\n            if row['start_frame'] < last_stop:\n                mask[i] = False\n            else:\n                last_stop = row['stop_frame']\n        group_list.append(group[mask])\n    submission = pd.concat(group_list) if group_list else submission\n\n    s_list = []\n    for _, row in dataset.iterrows():\n        lab_id = row['lab_id']\n        video_id = row['video_id']\n        if (submission.video_id == video_id).any():\n            continue\n\n        if verbose:\n            print(f\"Video {video_id} has no predictions\")\n\n        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n        vid = pd.read_parquet(path)\n\n        vid_behaviors = eval(row['behaviors_labeled'])\n        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n        vid_behaviors = [b.split(',') for b in vid_behaviors]\n        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n\n        start_frame = vid.video_frame.min()\n        stop_frame = vid.video_frame.max() + 1\n\n        for (agent, target), actions in vid_behaviors.groupby(['agent', 'target']):\n            batch_len = int(np.ceil((stop_frame - start_frame) / len(actions)))\n            for i, (_, action_row) in enumerate(actions.iterrows()):\n                batch_start = start_frame + i * batch_len\n                batch_stop = min(batch_start + batch_len, stop_frame)\n                s_list.append((video_id, agent, target, action_row['action'], batch_start, batch_stop))\n\n    if len(s_list) > 0:\n        submission = pd.concat([\n            submission,\n            pd.DataFrame(s_list, columns=['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame'])\n        ])\n\n    submission = submission.reset_index(drop=True)\n    return submission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:28:25.762907Z","iopub.execute_input":"2025-11-10T09:28:25.763178Z","iopub.status.idle":"2025-11-10T09:28:25.778439Z","shell.execute_reply.started":"2025-11-10T09:28:25.763161Z","shell.execute_reply":"2025-11-10T09:28:25.777851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def _clean_features(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Remove inf/NaN and keep memory small.\"\"\"\n    return (\n        df.replace([np.inf, -np.inf], np.nan)\n          .fillna(0.0)\n          .astype(np.float16, copy=False)\n    )\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==================== MAIN LOOP ====================\n\nsubmission_list = []\n\nfor section in range(len(body_parts_tracked_list)):\n    body_parts_tracked_str = body_parts_tracked_list[section]\n    # try:\n    body_parts_tracked = json.loads(body_parts_tracked_str)\n    print(f\"{section}. Processing: {len(body_parts_tracked)} body parts\")\n    if len(body_parts_tracked) > 5:\n        body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n\n    train_subset = train[train.body_parts_tracked == body_parts_tracked_str]\n\n    _fps_lookup = (\n        train_subset[['video_id', 'frames_per_second']]\n        .drop_duplicates('video_id')\n        .set_index('video_id')['frames_per_second']\n        .to_dict()\n    )\n\n    single_list, single_label_list, single_meta_list = [], [], []\n    pair_list, pair_label_list, pair_meta_list = [], [], []\n\n    for switch, data, meta, label in generate_mouse_data(train_subset, 'train'):\n        if switch == 'single':\n            single_list.append(data)\n            single_meta_list.append(meta)\n            single_label_list.append(label)\n        else:\n            pair_list.append(data)\n            pair_meta_list.append(meta)\n            pair_label_list.append(label)\n\n    if len(single_list) > 0:\n        single_frame_counts = [len(meta) for meta in single_meta_list]\n        total_single_frames = sum(single_frame_counts)\n        single_needs_sampling = total_single_frames > N_CUT\n\n        single_feats_parts = []\n        for idx, (data_i, meta_i, label_i, frames_i) in enumerate(\n            zip(single_list, single_meta_list, single_label_list, single_frame_counts)\n        ):\n            fps_i = _fps_from_meta(meta_i, _fps_lookup, default_fps=30.0)\n            Xi_full = transform_single(data_i, body_parts_tracked, fps_i).astype(np.float32)\n\n            if single_needs_sampling and frames_i > 0:\n                sample_n = int(round(N_CUT * (frames_i / total_single_frames)))\n                sample_n = min(len(Xi_full), max(1, sample_n))\n                # Stratify on \"any action active\" to keep positive/negative balance\n                y_arr = (label_i.sum(axis=1) > 0).astype(int).values\n                if verbose:\n                    counts = np.bincount(y_arr, minlength=2)\n                    # print(f\"[debug] single sampling | section={section} | frames={frames_i} | sample_n={sample_n} | counts={counts.tolist()}\")\n                # Ensure minimum positive share in the sampled set\n                rng = np.random.default_rng(SEED)\n                pos_idx = np.where(y_arr == 1)[0]\n                neg_idx = np.where(y_arr == 0)[0]\n                n_pos = len(pos_idx); n_neg = len(neg_idx)\n                target_pos = min(n_pos, max(int(round(n_pos*sample_n/frames_i)), int(round(sample_n * LEAST_POS_PERC)))) if n_pos > 0 else 0\n                target_neg = sample_n - target_pos\n                if np.min(np.bincount(y_arr, minlength=2)) < 2 or sample_n >= len(y_arr):\n                    strat_idx = rng.choice(len(y_arr), size=sample_n, replace=False)\n                else:\n                    # draw positives first (up to target_pos), rest from negatives\n                    pos_keep = rng.choice(pos_idx, size=target_pos, replace=False) if target_pos > 0 else np.array([], dtype=int)\n                    neg_keep = rng.choice(neg_idx, size=min(target_neg, n_neg), replace=False)\n                    strat_idx = np.concatenate([pos_keep, neg_keep])\n                    if len(strat_idx) < sample_n:\n                        # top up with any remaining samples if needed\n                        remain = sample_n - len(strat_idx)\n                        pool = np.setdiff1d(np.arange(len(y_arr)), strat_idx, assume_unique=False)\n                        extra = rng.choice(pool, size=min(remain, len(pool)), replace=False)\n                        strat_idx = np.concatenate([strat_idx, extra])\n                    rng.shuffle(strat_idx)\n                Xi = Xi_full.iloc[strat_idx]\n                meta_i = meta_i.iloc[strat_idx]\n                label_i = label_i.iloc[strat_idx]\n            else:\n                Xi = Xi_full\n\n            # keep meta/label aligned with sampled features\n            single_meta_list[idx] = meta_i\n            single_label_list[idx] = label_i\n            single_feats_parts.append(Xi)\n            del Xi\n\n        X_tr = pd.concat(single_feats_parts, axis=0, ignore_index=True)\n\n        single_label = pd.concat(single_label_list, axis=0, ignore_index=True)\n        single_meta  = pd.concat(single_meta_list,  axis=0, ignore_index=True)\n\n        del single_list, single_label_list, single_meta_list, single_feats_parts\n        gc.collect()\n\n        print(f\"  Single: {X_tr.shape}\")\n        submit_ensemble(body_parts_tracked_str, 'single', X_tr, single_label, single_meta)\n\n        del X_tr, single_label, single_meta\n        gc.collect()\n\n    if len(pair_list) > 0:\n        pair_frame_counts = [len(meta) for meta in pair_meta_list]\n        total_pair_frames = sum(pair_frame_counts)\n        pair_needs_sampling = total_pair_frames > N_CUT\n\n        pair_feats_parts = []\n        for idx, (data_i, meta_i, label_i, frames_i) in enumerate(\n            zip(pair_list, pair_meta_list, pair_label_list, pair_frame_counts)\n        ):\n            fps_i = _fps_from_meta(meta_i, _fps_lookup, default_fps=30.0)\n            Xi_full = transform_pair(data_i, body_parts_tracked, fps_i).astype(np.float32)\n\n            if pair_needs_sampling and frames_i > 0:\n                sample_n = int(round(N_CUT * (frames_i / total_pair_frames)))\n                sample_n = min(len(Xi_full), max(1, sample_n))\n                # Stratify on \"any action active\" to keep positive/negative balance\n                y_arr = (label_i.sum(axis=1) > 0).astype(int).values\n                if verbose:\n                    counts = np.bincount(y_arr, minlength=2)\n                    # print(f\"[debug] pair sampling | section={section} | frames={frames_i} | sample_n={sample_n} | counts={counts.tolist()}\")\n                rng = np.random.default_rng(SEED)\n                pos_idx = np.where(y_arr == 1)[0]\n                neg_idx = np.where(y_arr == 0)[0]\n                n_pos = len(pos_idx); n_neg = len(neg_idx)\n                target_pos = min(n_pos, max(int(round(n_pos*sample_n/frames_i)), int(round(sample_n * LEAST_POS_PERC)))) if n_pos > 0 else 0\n                target_neg = sample_n - target_pos\n                if np.min(np.bincount(y_arr, minlength=2)) < 2 or sample_n >= len(y_arr):\n                    strat_idx = rng.choice(len(y_arr), size=sample_n, replace=False)\n                else:\n                    pos_keep = rng.choice(pos_idx, size=target_pos, replace=False) if target_pos > 0 else np.array([], dtype=int)\n                    neg_keep = rng.choice(neg_idx, size=min(target_neg, n_neg), replace=False)\n                    strat_idx = np.concatenate([pos_keep, neg_keep])\n                    if len(strat_idx) < sample_n:\n                        remain = sample_n - len(strat_idx)\n                        pool = np.setdiff1d(np.arange(len(y_arr)), strat_idx, assume_unique=False)\n                        extra = rng.choice(pool, size=min(remain, len(pool)), replace=False)\n                        strat_idx = np.concatenate([strat_idx, extra])\n                    rng.shuffle(strat_idx)\n                Xi = Xi_full.iloc[strat_idx]\n                meta_i = meta_i.iloc[strat_idx]\n                label_i = label_i.iloc[strat_idx]\n            else:\n                Xi = Xi_full\n\n            pair_meta_list[idx] = meta_i\n            pair_label_list[idx] = label_i\n            pair_feats_parts.append(Xi)\n            del Xi\n\n        X_tr = pd.concat(pair_feats_parts, axis=0, ignore_index=True)\n\n        \n        pair_label = pd.concat(pair_label_list, axis=0, ignore_index=True)\n        pair_meta  = pd.concat(pair_meta_list,  axis=0, ignore_index=True)\n\n        del pair_list, pair_label_list, pair_meta_list, pair_feats_parts\n        gc.collect()\n\n        print(f\"  Pair: {X_tr.shape}\")\n        submit_ensemble(body_parts_tracked_str, 'pair', X_tr, pair_label, pair_meta)\n\n        del X_tr, pair_label, pair_meta\n        gc.collect()\n\n    # except Exception as e:\n    #     print(f'***Exception*** {str(e)}')\n\n    gc.collect()\n    print()\n\nif len(submission_list) > 0:\n    submission = pd.concat(submission_list, ignore_index=True)\nelse:\n    submission = pd.DataFrame({\n        'video_id': [438887472],\n        'agent_id': ['mouse1'],\n        'target_id': ['self'],\n        'action': ['rear'],\n        'start_frame': [278],\n        'stop_frame': [500]\n    })\n\nsubmission_robust = robustify(submission, test, 'test')\nsubmission_robust.index.name = 'row_id'\nsubmission_robust.to_csv('submission.csv')\nprint(f\"\\nSubmission created: {len(submission_robust)} predictions\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:28:25.779125Z","iopub.execute_input":"2025-11-10T09:28:25.7793Z"}},"outputs":[],"execution_count":null}]}